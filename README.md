# Reading papers: It is not about reading through the whole thing.

## Check reading / understanding progress
| Paper  |   20  |   40  |   60  |   80  | 100 | Scratch code | Reviewed |
|:---------|:-----|:------|:------|:------|:------|:------------| :---- | 
|Scratch neural net(MNIST)|  |           |           |           |           |  :heavy_check_mark:  |    |
|  [ImageNet Classification with Deep Convolutional Networks](https://papers.nips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) (AlexNet) | :heavy_check_mark: | :heavy_check_mark:  | :heavy_check_mark:  |:heavy_check_mark:   |:heavy_check_mark:  | :heavy_check_mark:  | https://velog.io/@iissaacc/AlexNet |
| [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) (VGGNet)| :heavy_check_mark:  |:heavy_check_mark:   | :heavy_check_mark:  |:heavy_check_mark:   |:heavy_check_mark:   |:heavy_check_mark:   | https://velog.io/@iissaacc/VGGNet   |
| [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)(GoogLeNet)  | :heavy_check_mark:  |:heavy_check_mark:   | :heavy_check_mark:  |:heavy_check_mark:   |:heavy_check_mark:   |:heavy_check_mark:   |  https://velog.io/@iissaacc/GoogLeNet   |
| [Some Improvements on Deep Convolutional Neural Network Based Image Classification](https://arxiv.org/abs/1312.5402)  | :heavy_check_mark:  |:heavy_check_mark:   | :heavy_check_mark:  |:heavy_check_mark:   |:heavy_check_mark:   |    |     |
| [Network in Network](https://arxiv.org/abs/1312.4400)  | :heavy_check_mark:  |:heavy_check_mark:   | :heavy_check_mark:  |:heavy_check_mark:   |:heavy_check_mark:   |   |https://velog.io/@iissaacc/Network-in-Network  |
| [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) (ResNet) |  :heavy_check_mark:  |:heavy_check_mark:   | :heavy_check_mark:  |:heavy_check_mark:   |:heavy_check_mark:   |:heavy_check_mark:   | https://velog.io/@iissaacc/ResNet  |
| [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946) |:heavy_check_mark:| :heavy_check_mark:  | :heavy_check_mark:  | :heavy_check_mark:  |   |:heavy_check_mark:   | https://velog.io/@iissaacc/EfficientNet  |
|  [Swish: a Self-Gated Activation Function](https://arxiv.org/abs/1710.05941v1)  |:heavy_check_mark:    |  :heavy_check_mark:  |  :heavy_check_mark:  |    |    |    |https://velog.io/@iissaacc/Swish-function    |
| [Squeeze-and-Excitation Networks](https://arxiv.org/abs/1709.01507)   | :heavy_check_mark:   | :heavy_check_mark:   | :heavy_check_mark:   |    |    |SE block & SE Residual block    | https://velog.io/@iissaacc/SENet   |
| [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)  | :heavy_check_mark:  |:heavy_check_mark:   |          |          |          | Depthwise Separable Convolution |[Depthwise Separable Convolution](https://velog.io/@iissaacc/Depthwise-Separable-Convolution)    |
|[MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381) |:heavy_check_mark: | :heavy_check_mark: |    |    |    |:heavy_check_mark: |    |
| [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)| :heavy_check_mark:  |:heavy_check_mark:   | :heavy_check_mark:  |:heavy_check_mark:   |:heavy_check_mark:   |   | https://velog.io/@iissaacc/Batch-Normalization-2015 |
|[Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186)    | :heavy_check_mark:   | :heavy_check_mark:   | :heavy_check_mark:   |    |    | :heavy_check_mark:   | https://velog.io/@iissaacc/Cyclical-Learning-Rate   |
| [How Does Batch Normalization Help Optimization?](https://arxiv.org/abs/1805.11604)  |:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|   |   |   |     |
| [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf)  |:heavy_check_mark:|:heavy_check_mark:|:heavy_check_mark:|   |   |   | https://velog.io/@iissaacc/Dropout    |
| [Feature Pyramid Networks for Object Detection](https://arxiv.org/abs/1612.03144) | :heavy_check_mark:  |:heavy_check_mark:   | :heavy_check_mark:  |:heavy_check_mark:   |     |:heavy_check_mark:   | https://velog.io/@iissaacc/Feature-Pyramid-Network   |
| [Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/abs/1311.2524) (R-CNN)| :heavy_check_mark:  |   |   |   |     |   |     |
| [Fast R-CNN](https://arxiv.org/abs/1504.08083)  | :heavy_check_mark:  |  |   |   |     |   | https://velog.io/@iissaacc/RoI-Pooling    |
| [Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/abs/1506.01497)  | :heavy_check_mark:  |:heavy_check_mark:   | :heavy_check_mark:  |:heavy_check_mark:   |     |RPN   |  https://velog.io/@iissaacc/Region-Proposal-Network   |
|[Mask R-CNN](https://arxiv.org/abs/1703.06870)    | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |    |    |    |
|[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)| :heavy_check_mark:  | :heavy_check_mark:  |    |    |    |    |    |
|[YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) |  :heavy_check_mark:  |  :heavy_check_mark:  |  :heavy_check_mark:  |    |    |    | https://velog.io/@iissaacc/YOLOv2    |
|[Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993)    |  :heavy_check_mark:  |  :heavy_check_mark:  |:heavy_check_mark:    |  :heavy_check_mark:  |    | :heavy_check_mark:   | https://velog.io/@iissaacc/DenseNet   |
| [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/abs/1503.03832)   | :heavy_check_mark:   | :heavy_check_mark:   |  :heavy_check_mark:  |    |    |    | https://velog.io/@iissaacc/Triplet-Loss   |
|[Decoupled Weight Decay Regularization](https://arxiv.org/abs/1711.05101)    | :heavy_check_mark:   | :heavy_check_mark:   | :heavy_check_mark:   |    |    | :heavy_check_mark:   | https://velog.io/@iissaacc/AdamW  |
| [SGDR: Stochastic Gradient Descent with Warm Restarts](https://arxiv.org/abs/1608.03983)   |  :heavy_check_mark:  |  :heavy_check_mark:  | :heavy_check_mark:   |    |    | :heavy_check_mark:   | https://velog.io/@iissaacc/SGDR   |
|[Deep Networks with Stochastic Depth](https://arxiv.org/abs/1603.09382)    |:heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark:   |  :heavy_check_mark:  |    |:heavy_check_mark:    | https://velog.io/@iissaacc/Stochastic-Depth-Network   |
|[Learning Deep Features for Discriminative Localization](https://arxiv.org/abs/1512.04150)    | :heavy_check_mark:   | :heavy_check_mark:    | :heavy_check_mark:    |    |    | :heavy_check_mark:   |https://velog.io/@iissaacc/Class-Activation-Mapping    |
| [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)   |  :heavy_check_mark:  | :heavy_check_mark:   | :heavy_check_mark:   |    |    | :heavy_check_mark:   | https://velog.io/@iissaacc/Knowledge-Distillation   |
|    |    |    |    |    |    |    |    |

## Dividing multiple parts.
1. Title / Abstract / Figuires
2. Intro / Conclusion / Figuires / Skimming the rest
3. Read but skip / skim math
4. Whole thing but skip the part that dosen't make sense.

## Answer the following question while reading
1. What did authors try to accomplish?
2. What were the key elements of the approach?
3. What can you use yourself?
4. What other references do you want to follow?

## Where to go for sources
1. Twitter 
2. ML subreddit 
3. Conferences e.g. NIPS, ICML, ICLR 
4. Friends

## Math
* Read through it, take detailed notes, rederive it form scratch

## Code
1. Run open source code
2. Reimplement from scratch

### Reference
* https://www.youtube.com/watch?v=733m6qBH-jI
